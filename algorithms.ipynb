{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a897a145",
   "metadata": {},
   "source": [
    "# Algorithm comparation & research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91414163",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install niapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48df1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from niapy.task import Task\n",
    "from niapy.algorithms.basic import (\n",
    "    FireflyAlgorithm,\n",
    "    ParticleSwarmOptimization,\n",
    "    GreyWolfOptimizer\n",
    ")\n",
    "from niapy.problems import Sphere, Rastrigin, Rosenbrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e653ef",
   "metadata": {},
   "source": [
    "## Benchmark functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fad87",
   "metadata": {},
   "source": [
    "### Sphere\n",
    "\n",
    "\\[\n",
    "    f(x) = \\sum^{D}_{i=1} x^2_i\n",
    "\\]\n",
    "\n",
    "* Unimodal\n",
    "* Convex\n",
    "* Single global minimum at x = 0\n",
    "* Smooth gradient, easy convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf40fde",
   "metadata": {},
   "source": [
    "### Rastrigin\n",
    "\n",
    "\\[\n",
    "    f(x) = 10D + \\sum^{D}_{i=1} (x^2_i - 10cos(2\\pi x_i))\n",
    "\\]\n",
    "\n",
    "* Multimodal\n",
    "* Non-convex\n",
    "* Many local minima and global minimum at x = 0\n",
    "* Difficult convergence and challenging for premature convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1999856f",
   "metadata": {},
   "source": [
    "### Rosenbrock\n",
    "\n",
    "\\[\n",
    "    f(x) = \\sum^{D-1}_{i=1} (100(x_{i+1} - x^2_i)^2 + (x_i - 1)^2)\n",
    "\\]\n",
    "\n",
    "* Unimodal\n",
    "* Non-convex\n",
    "* Global minimum at x = (1, 1, 1, \\dots, 1)\n",
    "* Narrow curved valley"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0f4c4",
   "metadata": {},
   "source": [
    "### Function parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e80a6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = {\n",
    "    \"Sphere\": (Sphere, {\n",
    "        \"lower\": -5.12,\n",
    "        \"upper\": 5.12,\n",
    "        \"max_evals\": 10000,\n",
    "    }),\n",
    "    \"Rastrigin\": (Rastrigin, {\n",
    "        \"lower\": -5.12,\n",
    "        \"upper\": 5.12,\n",
    "        \"max_evals\": 30000,\n",
    "    }),\n",
    "    \"Rosenbrock\": (Rosenbrock, {\n",
    "        \"lower\": -30,\n",
    "        \"upper\": 30,\n",
    "        \"max_evals\": 30000,\n",
    "    }),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e1d961",
   "metadata": {},
   "source": [
    "> **Note:** `niapy` already initializes algorithms with a uniform random distribution by default over the upper and lower bounds defined, so there is no need to apply transformations to the functions due to centering-around-zero bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82917976",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b37654",
   "metadata": {},
   "source": [
    "### Firefly Algorithm\n",
    "\n",
    "[Yang *et al*., 2009](https://link.springer.com/chapter/10.1007/978-3-642-04944-6_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d1845",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimization\n",
    "\n",
    "[Kennedy and Everhart, 1995](https://ieeexplore.ieee.org/document/488968)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587be4d2",
   "metadata": {},
   "source": [
    "### Grey Wolf Optimizer\n",
    "\n",
    "[Mirjalili *et al*., 2014](https://www.sciencedirect.com/science/article/pii/S0965997813001853?casa_token=Wm5JRdpOZrUAAAAA:Z8DWX5cN2vzQPpJ-9mOd-yUu7GkgJM1Lb_gA1owhmITuD3HKMZZyf3jZ75q43UfmEDc9MWu6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4eb22c",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e504d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"results\"\n",
    "PLOTS_DIR = os.path.join(RESULTS_DIR, \"plots\")\n",
    "TABLES_DIR = os.path.join(RESULTS_DIR, \"tables\")\n",
    "\n",
    "os.makedirs(PLOTS_DIR, exist_ok=True)\n",
    "os.makedirs(TABLES_DIR, exist_ok=True)\n",
    "\n",
    "N_RUNS = 30\n",
    "POPULATION_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b50548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = {\n",
    "    \"FA\": (FireflyAlgorithm, {\n",
    "        \"population_size\": 30,\n",
    "        \"alpha\": 0.8,\n",
    "        \"beta0\": 1.0,\n",
    "        \"gamma\": 0.1\n",
    "    }),\n",
    "    \"PSO\": (ParticleSwarmOptimization, { # Clerc's constriction coefficients\n",
    "        \"population_size\": 30,\n",
    "        \"w\": 0.729,\n",
    "        \"c1\": 1.49445,\n",
    "        \"c2\": 1.49445\n",
    "    }),\n",
    "    \"GWO\": (GreyWolfOptimizer, {\n",
    "        \"population_size\": 30\n",
    "    }),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c33881f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single(task, algorithm):\n",
    "    \"\"\"\n",
    "    Run a single instance of an algorithm on a Task.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task : Task\n",
    "        The optimization task to solve.\n",
    "    algorithm : Algorithm\n",
    "        The algorithm instance to run.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_position : np.ndarray\n",
    "        The best solution found.\n",
    "    best_fitness : float\n",
    "        The fitness value of the best solution.\n",
    "    \"\"\"\n",
    "    best_position, best_fitness = algorithm.run(task)\n",
    "    return best_position, best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e5de4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def benchmark_algorithm(algorithm_class, algorithm_params, problem_class, problem_params, n_runs=30, n_points=300, seed_start=0):\n",
    "    \"\"\"\n",
    "    Runs an algorithm multiple times on a problem and collect results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fitness_runs : np.ndarray\n",
    "        Best fitness from each run (length n_runs)\n",
    "    convergence_avg : np.ndarray\n",
    "        Averaged convergence curve interpolated onto a common x-axis (length n_points)\n",
    "    \"\"\"\n",
    "    fitness_runs = []\n",
    "    convergence_curves = []\n",
    "\n",
    "    evals_max = problem_params[\"max_evals\"]\n",
    "    x_common = np.linspace(0, evals_max, n_points)\n",
    "\n",
    "    for run_idx in range(seed_start, seed_start + n_runs):\n",
    "        np.random.seed(run_idx)\n",
    "\n",
    "        # Create task and algorithm\n",
    "        task = Task(\n",
    "            problem_class(**problem_params),\n",
    "            max_evals=problem_params[\"max_evals\"],\n",
    "            max_iters=problem_params[\"max_evals\"] // algorithm_params[\"population_size\"]\n",
    "        )\n",
    "        algo = algorithm_class(**algorithm_params)\n",
    "\n",
    "        # Run single optimization\n",
    "        best_position, best_fitness = algo.run(task)\n",
    "        fitness_runs.append(best_fitness)\n",
    "\n",
    "        # Get convergence data (function evaluations vs best fitness)\n",
    "        x, y = task.convergence_data(x_axis=\"evals\")\n",
    "\n",
    "        # Interpolate onto common x-axis\n",
    "        y_interp = np.interp(x_common, x, y)\n",
    "        convergence_curves.append(y_interp)\n",
    "\n",
    "    # Average convergence across runs\n",
    "    convergence_avg = np.mean(convergence_curves, axis=0)\n",
    "\n",
    "    return np.array(fitness_runs), convergence_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48e0b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_loop(problems, algorithms, *, dimension=30, n_runs=30, results_dir=\"results\", n_points=300):\n",
    "    \"\"\"\n",
    "    Runs benchmark for multiple algorithms on multiple problems.\n",
    "    Saves plots and summary table.\n",
    "    \"\"\"\n",
    "\n",
    "    plots_dir = os.path.join(results_dir, f\"{dimension}_d/plots\")\n",
    "    tables_dir = os.path.join(results_dir, f\"{dimension}_d/tables\")\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    os.makedirs(tables_dir, exist_ok=True)\n",
    "\n",
    "    summary_rows = []\n",
    "\n",
    "    for problem_name, (pclass, pconf) in problems.items():\n",
    "        plt.figure()\n",
    "        for algo_name, (algo_class, algo_params) in algorithms.items():\n",
    "            # Combine dimension with problem config\n",
    "            problem_params = {\"dimension\": dimension, **pconf}\n",
    "\n",
    "            # Run benchmark\n",
    "            fitness_runs, convergence_avg = benchmark_algorithm(\n",
    "                algo_class,\n",
    "                algo_params,\n",
    "                problem_class=pclass,\n",
    "                problem_params=problem_params,\n",
    "                n_runs=n_runs,\n",
    "                n_points=n_points\n",
    "            )\n",
    "\n",
    "            # Save summary statistics\n",
    "            summary_rows.append({\n",
    "                \"Problem\": problem_name,\n",
    "                \"Algorithm\": algo_name,\n",
    "                \"Mean fitness\": np.mean(fitness_runs),\n",
    "                \"Std fitness\": np.std(fitness_runs),\n",
    "                \"Best fitness\": np.min(fitness_runs),\n",
    "                \"Worst fitness\": np.max(fitness_runs),\n",
    "            })\n",
    "\n",
    "            # Plot convergence\n",
    "            plt.plot(np.linspace(0, problem_params[\"max_evals\"], n_points), convergence_avg, label=algo_name)\n",
    "\n",
    "        plt.title(f\"{problem_name} â€“ Convergence\")\n",
    "        plt.xlabel(\"Function evaluations\")\n",
    "        plt.ylabel(\"Best fitness\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plots_dir, f\"{problem_name}_convergence.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    # Save summary table\n",
    "    df_summary = pd.DataFrame(summary_rows)\n",
    "    df_summary.to_csv(os.path.join(tables_dir, \"summary.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01a85415",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_benchmark_loop(problems, algorithms, dimension=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1f6922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_benchmark_loop(problems, algorithms, dimension=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
